<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="en-us">
  <head>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>7 - Advanced Text Generation Techniques and Tools - Random Steps</title><meta name="author" content="Qianqian">
<meta name="description" content=""><meta name="keywords" content='LLM'>
  <meta itemprop="name" content="7 - Advanced Text Generation Techniques and Tools">
  <meta itemprop="datePublished" content="2025-09-27T03:27:17-07:00">
  <meta itemprop="dateModified" content="2025-09-27T03:27:17-07:00">
  <meta itemprop="wordCount" content="450">
  <meta itemprop="keywords" content="LLM"><meta property="og:url" content="https://qianqianshan.github.io/posts/advanced_text_generation_techniques_and_tools/">
  <meta property="og:site_name" content="Random Steps">
  <meta property="og:title" content="7 - Advanced Text Generation Techniques and Tools">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-09-27T03:27:17-07:00">
    <meta property="article:modified_time" content="2025-09-27T03:27:17-07:00">
    <meta property="article:tag" content="LLM">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="7 - Advanced Text Generation Techniques and Tools">
<meta name="application-name" content="FixIt">
<meta name="apple-mobile-web-app-title" content="FixIt"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="canonical" type="text/html" href="https://qianqianshan.github.io/posts/advanced_text_generation_techniques_and_tools/" title="7 - Advanced Text Generation Techniques and Tools - Random Steps" /><link rel="prev" type="text/html" href="https://qianqianshan.github.io/posts/prompt_engineering/" title="6 - Prompt Engineering" /><link rel="next" type="text/html" href="https://qianqianshan.github.io/posts/semantic_search_and_retrieval_augmented_generation/" title="8 - Semantic Search and Retrieval-Augmented Generation (RAG)" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="/lib/fontawesome-free/all.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/lib/animate/animate.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "7 - Advanced Text Generation Techniques and Tools",
    "inLanguage": "en-us",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https:\/\/qianqianshan.github.io\/posts\/advanced_text_generation_techniques_and_tools\/"
    },"genre": "posts","keywords": "LLM","wordcount":  450 ,
    "url": "https:\/\/qianqianshan.github.io\/posts\/advanced_text_generation_techniques_and_tools\/","datePublished": "2025-09-27T03:27:17-07:00","dateModified": "2025-09-27T03:27:17-07:00","publisher": {
      "@type": "Organization",
      "name": ""},"author": {
        "@type": "Person",
        "name": "Qianqian"
      },"description": ""
  }
  </script><script src="/js/head/color-scheme.min.js"></script></head>
  <body data-header-desktop="sticky" data-header-mobile="auto"><div class="wrapper" data-page-style="normal"><header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper">
    <div class="header-title">
      <a href="/" title="Random Steps"><span class="header-title-text">Random Steps</span></a><span class="header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a class="menu-link" href="/archives/"><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> Archives</a></li><li class="menu-item">
              <a class="menu-link" href="/categories/"><i class="fa-solid fa-folder-tree fa-fw fa-sm" aria-hidden="true"></i> Categories</a></li><li class="menu-item">
              <a class="menu-link" href="/tags/"><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> Tags</a></li><li class="menu-item delimiter"></li><li class="menu-item theme-switch" title="Switch Theme">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li></ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/" title="Random Steps"><span class="header-title-text">Random Steps</span></a><span class="header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li class="menu-item"><a class="menu-link" href="/archives/"><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> Archives</a></li><li class="menu-item"><a class="menu-link" href="/categories/"><i class="fa-solid fa-folder-tree fa-fw fa-sm" aria-hidden="true"></i> Categories</a></li><li class="menu-item"><a class="menu-link" href="/tags/"><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden="true"></i> Tags</a></li><li class="menu-item menu-system">
          <span class="menu-system-item theme-switch" title="Switch Theme"><i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i></span></li>
      </ul>
    </nav>
  </div>
</header><main class="container"><aside class="aside-collection animate__animated animate__fadeIn animate__faster" aria-label="Collections"></aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX"><span title="Repost" class="icon-repost"><i class="fa-solid fa-share fa-fw" aria-hidden="true"></i></span><span>7 - Advanced Text Generation Techniques and Tools</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      Qianqian</span></span><span class="post-included-in">&nbsp;included in <a href="/categories/hands-on-large-language-models/" class="post-category" title="Category - Hands-on Large Language Models"><i class="fa-regular fa-folder fa-fw" aria-hidden="true"></i> Hands-on Large Language Models</a></span></div><div class="post-meta-line"><span title="published on 2025-09-27 03:27:17"><i class="fa-solid fa-calendar-days fa-fw me-1" aria-hidden="true"></i><time datetime="2025-09-27">2025-09-27</time></span>&nbsp;<span title="450 words"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden="true"></i>About 500 words</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden="true"></i>3 minutes</span>&nbsp;</div>
    </div><div class="details toc" id="toc-static" data-kept="false">
        <div class="details-summary toc-title">
          <span>Contents</span>
          <span><i class="details-icon fa-solid fa-angle-right" aria-hidden="true"></i></span>
        </div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#model-io">Model I/O</a>
      <ul>
        <li><a href="#loading-quantized-models-with-langchain">Loading Quantized Models with LangChain</a></li>
        <li><a href="#chains-extending-the-capabilities-of-llms">Chains: Extending the Capabilities of LLMs</a></li>
      </ul>
    </li>
    <li><a href="#memory-helping-llms-to-remember-conversations">Memory: Helping LLMs to Remember Conversations</a></li>
    <li><a href="#agents-creating-a-system-of-llms">Agents: Creating a System of LLMs</a></li>
  </ul>
</nav></div>
      </div><div class="content" id="content"><p>What can we do to further enhance the experience and output that we get from LLM without fine-tuning the model? There are several techniques that are available as shown in the figure below.</p>
<figure>
  <img src="/images/hands-on-LLM/07-01.jpg" alt="LLM system components example" width="50%" />
  <figcaption>Fig. Modular components of LangChain that can be chained to allow for complex LLM systems.</figcaption>
</figure>
<h2 class="heading-element" id="model-io"><span>Model I/O</span>
  <a href="#model-io" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><h3 class="heading-element" id="loading-quantized-models-with-langchain"><span>Loading Quantized Models with LangChain</span>
  <a href="#loading-quantized-models-with-langchain" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><p>Quantization is a method to compress the original model by reducing the precision of the values (e.g., 32-bit to 16-bit representation) without removing vital information. So it will be much faster to run the model with less VRAM.</p>
<h3 class="heading-element" id="chains-extending-the-capabilities-of-llms"><span>Chains: Extending the Capabilities of LLMs</span>
  <a href="#chains-extending-the-capabilities-of-llms" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h3><ul>
<li>By chaining prompt template to an LLM, we only need to define the input prompts,
and the template will be constructed for you.</li>
<li>When lengthy and complex prompts are required, we can break it into smaller sub-tasks to run sequentially, and it will require multiple calls to the LLM but with smaller prompts and intermediate outputs are available.</li>
</ul>
<h2 class="heading-element" id="memory-helping-llms-to-remember-conversations"><span>Memory: Helping LLMs to Remember Conversations</span>
  <a href="#memory-helping-llms-to-remember-conversations" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>To make the models stateful with memory of previous conversations, we can add specific types of memory, more details in the summarization table below.</p>
<table>
  <thead>
      <tr>
          <th>Memory type</th>
          <th>Description</th>
          <th>Pros</th>
          <th>Cons</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Conversation Buffer</strong></td>
          <td>Copy the full conversation history and paste it into the prompt</td>
          <td>- Easiest implementation<br>- Ensures no information loss within context window</td>
          <td>- Slower generation speed as more tokens are needed<br>- Only suitable for large-context LLMs<br>- Larger chat histories make information retrieval difficult</td>
      </tr>
      <tr>
          <td><strong>Windowed Conversation Buffer</strong></td>
          <td>Use the last <em>k</em> conversations instead of the full chat history</td>
          <td>- Large-context LLMs are not needed unless chat history is large<br>- No information loss over the last <em>k</em> interactions</td>
          <td>- Only captures the last <em>k</em> interactions<br>- No compression of the last <em>k</em> interactions</td>
      </tr>
      <tr>
          <td><strong>Conversation Summary</strong></td>
          <td>Summarize the entire conversation and distill it into the main points</td>
          <td>- Captures the full history<br>- Enables long conversations<br>- Reduces tokens needed to capture full history</td>
          <td>- An additional call is necessary for each interaction<br>- Quality is reliant on the LLM’s summarization capabilities</td>
      </tr>
  </tbody>
</table>
<h2 class="heading-element" id="agents-creating-a-system-of-llms"><span>Agents: Creating a System of LLMs</span>
  <a href="#agents-creating-a-system-of-llms" class="heading-mark">
    <svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg>
  </a>
</h2><p>Agents are systems that leverage a language model to determine which actions they should take with what order. They can use everything we&rsquo;ve discussed so far such as model I/O, chains, memory, and can extend to two vital components:</p>
<ol>
<li><em>Tools</em> that the agent can use to do things it couldn&rsquo;t do itself (e.g., query internal DB)</li>
<li>The <em>agent type</em> which plans the actions to take or tools to use</li>
</ol>
<p>The driving force of many agent-based systmes is the use of a framework called <em>Reasoning and Acting (ReAct)</em>, it combines two important concepts in behavior: reasoning and acting - it iteratively follows the three steps: thought, action, and observation.</p></div><div class="post-footer" id="post-footer">
  <div class="post-info">
    <div class="post-info-line">
      <div class="post-info-mod">
        <span title="Updated on 2025-09-27 03:27:17">Updated on 2025-09-27&nbsp;</span>
      </div></div><div class="post-info-line">
        <div class="post-info-md"></div>
        <div class="post-info-share">
          <span><a href="javascript:void(0);" title="Share on X" data-sharer="twitter" data-url="https://qianqianshan.github.io/posts/advanced_text_generation_techniques_and_tools/" data-title="7 - Advanced Text Generation Techniques and Tools" data-hashtags="LLM"><i class="fa-brands fa-x-twitter fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://qianqianshan.github.io/posts/advanced_text_generation_techniques_and_tools/" data-hashtag="LLM"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden="true"></i></a>
  <a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://qianqianshan.github.io/posts/advanced_text_generation_techniques_and_tools/" data-title="7 - Advanced Text Generation Techniques and Tools"><i class="fa-brands fa-weibo fa-fw" aria-hidden="true"></i></a>
  </span>
        </div>
      </div></div>

  <div class="post-info-more">
    <section class="post-tags"><i class="fa-solid fa-tags fa-fw me-1" aria-hidden="true"></i><a href="/tags/llm/" class="post-tag" title="Tags - LLM">LLM</a></section>
    <section>
      <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
    </section>
  </div><div class="post-nav"><a href="/posts/prompt_engineering/" class="post-nav-item" rel="prev" title="6 - Prompt Engineering"><i class="fa-solid fa-angle-left fa-fw" aria-hidden="true"></i>6 - Prompt Engineering</a><a href="/posts/semantic_search_and_retrieval_augmented_generation/" class="post-nav-item" rel="next" title="8 - Semantic Search and Retrieval-Augmented Generation (RAG)">8 - Semantic Search and Retrieval-Augmented Generation (RAG)<i class="fa-solid fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article>

  <aside class="toc" id="toc-auto" aria-label="Contents"><h2 class="toc-title">Contents&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden="true"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside></main><footer class="footer">
    <div class="footer-container"><div class="footer-line powered">Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow noopener noreferrer" title="Hugo 0.148.2"><img class="hugo-icon" src="/images/hugo.min.svg" alt="Hugo logo" /> Hugo</a> | Theme - <a href="https://github.com/hugo-fixit/FixIt" target="_blank" rel="external" title="FixIt v0.4.0-alpha-20250805041424-57ccd470"><img class="fixit-icon" src="/images/fixit.min.svg" alt="FixIt logo" /> FixIt</a>
        </div><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">2025</span><span class="author" itemprop="copyrightHolder">
              <a href="/"></a></span></div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="Back to Top"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric d-none">0%</span>
        </div></div><div id="mask"></div><noscript>
    <div class="noscript-warning">This website works best with JavaScript enabled.</div>
  </noscript>
</div><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script src="/lib/sharer/sharer.min.js" async defer></script><script src="/lib/cookieconsent/cookieconsent.min.js" defer></script><script>window.config={"code":{"copyTitle":"Copy to clipboard","editLockTitle":"Lock editable code block","editUnLockTitle":"Unlock editable code block","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"version":"v0.4.0-alpha-20250805041424-57ccd470"};</script><script src="/js/theme.min.js" defer></script></body>
</html>
